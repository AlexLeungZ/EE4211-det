{"cells":[{"cell_type":"code","execution_count":null,"id":"8UVQJcCZMZz7","metadata":{"id":"8UVQJcCZMZz7"},"outputs":[],"source":["import os\n","from PIL import Image\n","import numpy as np\n","\n","f = open('/home/cyang/EE4211-Det/ML-based/data/dataset/BirdData/train.csv')\n","\n","line = f.readline()\n","while line:\n","    if 'jpg' in line:\n","        info = line.split(' ')\n","        image = Image.open(os.path.join('/home/cyang/EE4211-Det/ML-based/data/dataset/BirdData/Train', info[0][:-1]))\n","        seg = Image.open(os.path.join('/home/cyang/EE4211-Det/ML-based/data/dataset/BirdData/segmentations', info[0][:-1]).replace('jpg', 'png')).convert('L')\n","        seg = np.array(seg)\n","        seg_index = np.where(seg == 255)\n","        x_min = np.min(seg_index[1])\n","        x_max = np.max(seg_index[1])\n","        y_min = np.min(seg_index[0])\n","        y_max = np.max(seg_index[0])\n","        print(seg_index)\n","        w, h = image.size\n","        print(w, h)\n","        print(x_min, y_min, x_max, y_max)\n","        if w >= h:\n","            if w-x_max > x_min:\n","                neg = image.crop((x_max, 0, w, h))\n","            else:\n","                neg = image.crop((0, 0, x_min, h))\n","            if max(w-x_max, x_min) < 20:\n","                pass\n","            else:\n","                neg.save(os.path.join('/home/cyang/EE4211-Det/ML-based/data/dataset/BirdData/neg', info[0][:-1]).replace('jpg', 'png'))\n","        else:\n","            if h-y_max > y_min:\n","                neg = image.crop((0, y_max, w, h))\n","            else:\n","                neg = image.crop((0, 0, w, y_min))\n","            if max(h-y_max, y_min) < 20:\n","                pass\n","            else:\n","                neg.save(os.path.join('/home/cyang/EE4211-Det/ML-based/data/dataset/BirdData/neg', info[0][:-1]).replace('jpg', 'png'))\n","        pos = image.crop((x_min, y_min, x_max, y_max))\n","        # print(os.path.join('/home/cyang/EE4211-Det/ML-based/data/dataset/BirdData/pos', info[0][:-1]))\n","        pos.save(os.path.join('/home/cyang/EE4211-Det/ML-based/data/dataset/BirdData/pos', info[0][:-1]).replace('jpg', 'png'))\n","\n","        # print(info)\n","    line = f.readline()\n","f.close()\n"]},{"cell_type":"code","execution_count":6,"id":"d7269091","metadata":{},"outputs":[],"source":["import sys\n","sys.path.append(\"object-detector\")"]},{"cell_type":"code","execution_count":7,"id":"f4644c11","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-03-29T07:46:27.866428Z","iopub.status.busy":"2022-03-29T07:46:27.865285Z","iopub.status.idle":"2022-03-29T07:46:29.527483Z","shell.execute_reply":"2022-03-29T07:46:29.526840Z"},"id":"f4644c11","outputId":"988fa885-c9ae-472e-b206-1e2f6a56fe57","papermill":{"duration":1.672416,"end_time":"2022-03-29T07:46:29.527773","exception":true,"start_time":"2022-03-29T07:46:27.855357","status":"failed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["<>:40: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","<>:40: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'ConfigParser'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\chunc\\Documents\\Git\\ee4211-det\\ml-based.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chunc/Documents/Git/ee4211-det/ml-based.ipynb#ch0000001?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mglob\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chunc/Documents/Git/ee4211-det/ml-based.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chunc/Documents/Git/ee4211-det/ml-based.ipynb#ch0000001?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chunc/Documents/Git/ee4211-det/ml-based.ipynb#ch0000001?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chunc/Documents/Git/ee4211-det/ml-based.ipynb#ch0000001?line=12'>13</a>\u001b[0m     \u001b[39m# Parse the command line arguments\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chunc/Documents/Git/ee4211-det/ml-based.ipynb#ch0000001?line=13'>14</a>\u001b[0m     parser \u001b[39m=\u001b[39m ap\u001b[39m.\u001b[39mArgumentParser()\n","File \u001b[1;32mc:\\Users\\chunc\\Documents\\Git\\ee4211-det\\object-detector\\config.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///c%3A/Users/chunc/Documents/Git/ee4211-det/object-detector/config.py?line=0'>1</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/chunc/Documents/Git/ee4211-det/object-detector/config.py?line=1'>2</a>\u001b[0m \u001b[39mSet the config variable.\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/chunc/Documents/Git/ee4211-det/object-detector/config.py?line=2'>3</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m----> <a href='file:///c%3A/Users/chunc/Documents/Git/ee4211-det/object-detector/config.py?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mConfigParser\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcp\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/chunc/Documents/Git/ee4211-det/object-detector/config.py?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/chunc/Documents/Git/ee4211-det/object-detector/config.py?line=7'>8</a>\u001b[0m config \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mRawConfigParser()\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ConfigParser'"]}],"source":["# Import the required modules\n","from skimage.feature import local_binary_pattern\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","# from sklearn.externals import joblib\n","import joblib\n","import argparse as ap\n","import glob\n","import os\n","from config import *\n","\n","if __name__ == \"__main__\":\n","    # Parse the command line arguments\n","    parser = ap.ArgumentParser()\n","    parser.add_argument('-p', \"--posfeat\", help=\"Path to the positive features directory\", required=True)\n","    parser.add_argument('-n', \"--negfeat\", help=\"Path to the negative features directory\", required=True)\n","    parser.add_argument('-c', \"--classifier\", help=\"Classifier to be used\", default=\"LIN_SVM\")\n","    args = vars(parser.parse_args())\n","\n","    pos_feat_path =  args[\"posfeat\"]\n","    neg_feat_path = args[\"negfeat\"]\n","\n","    # Classifiers supported\n","    clf_type = args['classifier']\n","\n","    fds = []\n","    labels = []\n","    # Load the positive features\n","    for feat_path in glob.glob(os.path.join(pos_feat_path,\"*.feat\")):\n","        fd = joblib.load(feat_path)\n","        fds.append(fd)\n","        labels.append(1)\n","\n","    # Load the negative features\n","    for feat_path in glob.glob(os.path.join(neg_feat_path,\"*.feat\")):\n","        fd = joblib.load(feat_path)\n","        fds.append(fd)\n","        labels.append(0)\n","\n","    if clf_type is \"LIN_SVM\":\n","        clf = LinearSVC()\n","        print(\"Training a Linear SVM Classifier\")\n","        clf.fit(fds, labels)\n","        # If feature directories don't exist, create them\n","        if not os.path.isdir(os.path.split(model_path)[0]):\n","            os.makedirs(os.path.split(model_path)[0])\n","        joblib.dump(clf, model_path)\n","        print(\"Classifier saved to {}\".format(model_path))\n"]},{"cell_type":"code","execution_count":3,"id":"ad521427","metadata":{"id":"ad521427","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[{"ename":"TabError","evalue":"inconsistent use of tabs and spaces in indentation (nms.py, line 44)","output_type":"error","traceback":["Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n","  File \u001b[0;32mC:\\ProgramData\\Anaconda3\\envs\\dlearn\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3369\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n","\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m in \u001b[1;35m<cell line: 9>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from nms import nms\u001b[0m\n","\u001b[1;36m  File \u001b[1;32mc:\\Users\\chunc\\Documents\\Git\\ee4211-det\\object-detector\\nms.py:44\u001b[1;36m\u001b[0m\n\u001b[1;33m    return []\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mTabError\u001b[0m\u001b[1;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"]}],"source":["# Import the required modules\n","from skimage.transform import pyramid_gaussian\n","from skimage.io import imread\n","from skimage.feature import hog\n","# from sklearn.externals import joblib\n","import joblib\n","import cv2\n","import argparse as ap\n","from nms import nms\n","from config import *\n","\n","def sliding_window(image, window_size, step_size):\n","    '''\n","    This function returns a patch of the input image `image` of size equal\n","    to `window_size`. The first image returned top-left co-ordinates (0, 0) \n","    and are increment in both x and y directions by the `step_size` supplied.\n","    So, the input parameters are -\n","    * `image` - Input Image\n","    * `window_size` - Size of Sliding Window\n","    * `step_size` - Incremented Size of Window\n","\n","    The function returns a tuple -\n","    (x, y, im_window)\n","    where\n","    * x is the top-left x co-ordinate\n","    * y is the top-left y co-ordinate\n","    * im_window is the sliding window image\n","    '''\n","    for y in range(0, image.shape[0], step_size[1]):\n","        for x in range(0, image.shape[1], step_size[0]):\n","            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n","\n","if __name__ == \"__main__\":\n","    # Parse the command line arguments\n","    parser = ap.ArgumentParser()\n","    parser.add_argument('-i', \"--image\", help=\"Path to the test image\", required=True)\n","    parser.add_argument('-d','--downscale', help=\"Downscale ratio\", default=1.25,\n","            type=int)\n","    parser.add_argument('-v', '--visualize', help=\"Visualize the sliding window\",\n","            action=\"store_true\")\n","    args = vars(parser.parse_args())\n","\n","    # Read the image\n","    im = imread(args[\"image\"], as_gray=False)\n","    min_wdw_sz = (100, 40)\n","    step_size = (10, 10)\n","    downscale = args['downscale']\n","    visualize_det = args['visualize']\n","\n","    # Load the classifier\n","    clf = joblib.load(model_path)\n","\n","    # List to store the detections\n","    detections = []\n","    # The current scale of the image\n","    scale = 0\n","    # Downscale the image and iterate\n","    for im_scaled in pyramid_gaussian(im, downscale=downscale):\n","        # This list contains detections at the current scale\n","        cd = []\n","        # If the width or height of the scaled image is less than\n","        # the width or height of the window, then end the iterations.\n","        if im_scaled.shape[0] < min_wdw_sz[1] or im_scaled.shape[1] < min_wdw_sz[0]:\n","            break\n","        for (x, y, im_window) in sliding_window(im_scaled, min_wdw_sz, step_size):\n","            if im_window.shape[0] != min_wdw_sz[1] or im_window.shape[1] != min_wdw_sz[0]:\n","                continue\n","            # Calculate the HOG features\n","            fd = hog(im_window, orientations, pixels_per_cell, cells_per_block)\n","            fd = [fd]\n","            pred = clf.predict(fd)\n","            if pred == 1:\n","                print(\"Detection:: Location -> ({}, {})\".format(x, y))\n","                print(\"Scale ->  {} | Confidence Score {} \\n\".format(scale,clf.decision_function(fd)))\n","                detections.append((x, y, clf.decision_function(fd),\n","                    int(min_wdw_sz[0]*(downscale**scale)),\n","                    int(min_wdw_sz[1]*(downscale**scale))))\n","                cd.append(detections[-1])\n","            # If visualize is set to true, display the working\n","            # of the sliding window\n","            if visualize_det:\n","                clone = im_scaled.copy()\n","                for x1, y1, _, _, _  in cd:\n","                    # Draw the detections at this scale\n","                    cv2.rectangle(clone, (x1, y1), (x1 + im_window.shape[1], y1 +\n","                        im_window.shape[0]), (0, 0, 0), thickness=2)\n","                cv2.rectangle(clone, (x, y), (x + im_window.shape[1], y +\n","                    im_window.shape[0]), (255, 255, 255), thickness=2)\n","                # cv2.imshow(\"Sliding Window in Progress\", clone)\n","                # cv2.waitKey(30)\n","                cv2.imwrite('progress.png', clone)\n","        # Move the the next scale\n","        scale+=1\n","\n","    # Display the results before performing NMS\n","    clone = im.copy()\n","    for (x_tl, y_tl, _, w, h) in detections:\n","        # Draw the detections\n","        cv2.rectangle(im, (x_tl, y_tl), (x_tl+w, y_tl+h), (0, 0, 0), thickness=2)\n","    # cv2.imshow(\"Raw Detections before NMS\", im)\n","    # cv2.waitKey()\n","    cv2.imwrite('before_nms.png', im)\n","\n","    # Perform Non Maxima Suppression\n","    detections = nms(detections, threshold)\n","\n","    # Display the results after performing NMS\n","    for (x_tl, y_tl, _, w, h) in detections:\n","        # Draw the detections\n","        cv2.rectangle(clone, (x_tl, y_tl), (x_tl+w,y_tl+h), (0, 0, 0), thickness=2)\n","    # cv2.imshow(\"Final Detections after applying NMS\", clone)\n","    # cv2.waitKey()\n","    cv2.imwrite('after_nms.png', clone)"]},{"cell_type":"code","execution_count":null,"id":"ea0f1adf","metadata":{"id":"ea0f1adf","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["def overlapping_area(detection_1, detection_2):\n","    '''\n","    Function to calculate overlapping area'si\n","    `detection_1` and `detection_2` are 2 detections whose area\n","    of overlap needs to be found out.\n","    Each detection is list in the format ->\n","    [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n","    The function returns a value between 0 and 1,\n","    which represents the area of overlap.\n","    0 is no overlap and 1 is complete overlap.\n","    Area calculated from ->\n","    http://math.stackexchange.com/questions/99565/simplest-way-to-calculate-the-intersect-area-of-two-rectangles\n","    '''\n","    # Calculate the x-y co-ordinates of the \n","    # rectangles\n","    x1_tl = detection_1[0]\n","    x2_tl = detection_2[0]\n","    x1_br = detection_1[0] + detection_1[3]\n","    x2_br = detection_2[0] + detection_2[3]\n","    y1_tl = detection_1[1]\n","    y2_tl = detection_2[1]\n","    y1_br = detection_1[1] + detection_1[4]\n","    y2_br = detection_2[1] + detection_2[4]\n","    # Calculate the overlapping Area\n","    x_overlap = max(0, min(x1_br, x2_br)-max(x1_tl, x2_tl))\n","    y_overlap = max(0, min(y1_br, y2_br)-max(y1_tl, y2_tl))\n","    overlap_area = x_overlap * y_overlap\n","    area_1 = detection_1[3] * detection_2[4]\n","    area_2 = detection_2[3] * detection_2[4]\n","    total_area = area_1 + area_2 - overlap_area\n","    return overlap_area / float(total_area)\n","\n","def nms(detections, threshold=.9):\n","    '''\n","    This function performs Non-Maxima Suppression.\n","    `detections` consists of a list of detections.\n","    Each detection is in the format ->\n","    [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n","    If the area of overlap is greater than the `threshold`,\n","    the area with the lower confidence score is removed.\n","    The output is a list of detections.\n","    '''\n","    if len(detections) == 0:\n","        return []\n","    # Sort the detections based on confidence score\n","    detections = sorted(detections, key=lambda detections: detections[2],\n","            reverse=True)\n","    # Unique detections will be appended to this list\n","    new_detections=[]\n","    # Append the first detection\n","    new_detections.append(detections[0])\n","    # Remove the detection from the original list\n","    del detections[0]\n","    # For each detection, calculate the overlapping area\n","    # and if area of overlap is less than the threshold set\n","    # for the detections in `new_detections`, append the \n","    # detection to `new_detections`.\n","    # In either case, remove the detection from `detections` list.\n","    for index, detection in enumerate(detections):\n","        for new_detection in new_detections:\n","            if overlapping_area(detection, new_detection) > threshold:\n","                del detections[index]\n","                break\n","        else:\n","            new_detections.append(detection)\n","            del detections[index]\n","    return new_detections\n","\n","if __name__ == \"__main__\":\n","    # Example of how to use the NMS Module\n","    detections = [[31, 31, .9, 10, 10], [31, 31, .12, 10, 10], [100, 34, .8,10, 10]]\n","    print(\"Detections before NMS = {}\".format(detections))\n","    print(\"Detections after NMS = {}\".format(nms(detections)))\n"]},{"cell_type":"code","execution_count":null,"id":"7661f234","metadata":{"id":"7661f234","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["# Import the functions to calculate feature descriptors\n","from skimage.feature import local_binary_pattern\n","from skimage.feature import hog\n","from skimage.io import imread\n","# from sklearn.externals import joblib\n","import joblib\n","# To read file names\n","import argparse as ap\n","import glob\n","import os\n","from config import *\n","\n","if __name__ == \"__main__\":\n","    # Argument Parser\n","    parser = ap.ArgumentParser()\n","    parser.add_argument('-p', \"--pospath\", help=\"Path to positive images\",\n","            required=True)\n","    parser.add_argument('-n', \"--negpath\", help=\"Path to negative images\",\n","            required=True)\n","    parser.add_argument('-d', \"--descriptor\", help=\"Descriptor to be used -- HOG\",\n","            default=\"HOG\")\n","    args = vars(parser.parse_args())\n","\n","    pos_im_path = args[\"pospath\"]\n","    neg_im_path = args[\"negpath\"]\n","\t\n","    des_type = args[\"descriptor\"]\n","\n","    # If feature directories don't exist, create them\n","    if not os.path.isdir(pos_feat_ph):\n","        os.makedirs(pos_feat_ph)\n","\n","    # If feature directories don't exist, create them\n","    if not os.path.isdir(neg_feat_ph):\n","        os.makedirs(neg_feat_ph)\n","\n","    print(\"Calculating the descriptors for the positive samples and saving them\")\n","    for im_path in glob.glob(os.path.join(pos_im_path, \"*\")):\n","        im = imread(im_path, as_gray=True)\n","        if des_type == \"HOG\":\n","            fd = hog(im, orientations, pixels_per_cell, cells_per_block)\n","        fd_name = os.path.split(im_path)[1].split(\".\")[0] + \".feat\"\n","        fd_path = os.path.join(pos_feat_ph, fd_name)\n","        joblib.dump(fd, fd_path)\n","    print(\"Positive features saved in {}\".format(pos_feat_ph))\n","\n","    print(\"Calculating the descriptors for the negative samples and saving them\")\n","    for im_path in glob.glob(os.path.join(neg_im_path, \"*\")):\n","        im = imread(im_path, as_gray=True)\n","        if des_type == \"HOG\":\n","            fd = hog(im,  orientations, pixels_per_cell, cells_per_block)\n","        fd_name = os.path.split(im_path)[1].split(\".\")[0] + \".feat\"\n","        fd_path = os.path.join(neg_feat_ph, fd_name)\n","        joblib.dump(fd, fd_path)\n","    print(\"Negative features saved in {}\".format(neg_feat_ph))\n","\n","    print(\"Completed calculating features from training images\")\n"]},{"cell_type":"code","execution_count":null,"id":"805adbb0","metadata":{"id":"805adbb0","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["'''\n","Set the config variable.\n","'''\n","\n","import configparser as cp\n","import json\n","\n","config = cp.RawConfigParser()\n","config.read('../data/config/config.cfg')\n","\n","min_wdw_sz = json.loads(config.get(\"hog\",\"min_wdw_sz\"))\n","step_size = json.loads(config.get(\"hog\", \"step_size\"))\n","orientations = config.getint(\"hog\", \"orientations\")\n","pixels_per_cell = json.loads(config.get(\"hog\", \"pixels_per_cell\"))\n","cells_per_block = json.loads(config.get(\"hog\", \"cells_per_block\"))\n","visualize = config.getboolean(\"hog\", \"visualize\")\n","normalize = config.getboolean(\"hog\", \"normalize\")\n","pos_feat_ph = config.get(\"paths\", \"pos_feat_ph\")\n","neg_feat_ph = config.get(\"paths\", \"neg_feat_ph\")\n","model_path = config.get(\"paths\", \"model_path\")\n","threshold = config.getfloat(\"nms\", \"threshold\")\n"]},{"cell_type":"code","execution_count":null,"id":"ecEmftvdQzCR","metadata":{"id":"ecEmftvdQzCR"},"outputs":[],"source":["#!/usr/bin/python\n","import os\n","\n","\n","# Extract the features\n","pos_path = \"../data/dataset/BirdData/pos\"\n","neg_path = \"../data/dataset/BirdData/neg\"\n","os.system(\"python ../object-detector/extract-features.py -p {} -n {}\".format(pos_path, neg_path))\n","\n","# Perform training\n","pos_feat_path =  \"../data/features/pos\"\n","neg_feat_path =  \"../data/features/neg\"\n","os.system(\"python ../object-detector/train-classifier.py -p {} -n {}\".format(pos_feat_path, neg_feat_path))\n","\n","# Perform testing \n","test_im_path = \"/home/cyang/EE4211-Det/ML-based/data/dataset/BirdData/Test/1000.jpg\"\n","os.system(\"python ../object-detector/test-classifier.py -i {}\".format(test_im_path))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ml-based.ipynb","provenance":[]},"interpreter":{"hash":"77f34d046d5d0179e113d1366d3c45e53ba0cdc46f048bf565ee04a481ea0b26"},"kernelspec":{"display_name":"Python 3.9.12 ('dlearn')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"papermill":{"default_parameters":{},"duration":10.339531,"end_time":"2022-03-29T07:46:30.244335","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-03-29T07:46:19.904804","version":"2.3.3"}},"nbformat":4,"nbformat_minor":5}
